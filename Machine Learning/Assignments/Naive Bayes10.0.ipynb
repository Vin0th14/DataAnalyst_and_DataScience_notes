{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7ixKaNeVV1g"
      },
      "source": [
        "# <u><center>Naive Bayes Algorithms</center></u>\n",
        "\n",
        "\n",
        "Naive Bayes models is one of the simplest supervised learning algorithms. Naive Bayes classifier is the fast, accurate and reliable algorithm. Naive Bayes classifiers have high accuracy and speed on large datasets.\n",
        "\n",
        "As the name suggested Naive Bayes is based on **Bayes Theorem**. It assumes that the effect of a particular feature in a class is independent of other features. For example, a loan applicant is desirable or not depending on his/her income, previous loan and transaction history, age, and location. Even if these features are interdependent, these features are still considered independently. This assumption simplifies computation, and that's why it is considered as **naive.**\n",
        "\n",
        "So here it is important to know what is Bayes theorem. \n",
        "Bayes’ Theorem provides a way that we can calculate the probability of a piece of data belonging to a given class, given our prior knowledge. Bayes’ Theorem is stated as:\n",
        "\n",
        "\n",
        "**P(class|data) = (P(data|class) * P(class)) / P(data)**\n",
        "\n",
        "Where P(class|data) is the probability of class given the provided data.\n",
        "\n",
        "    Lets get started with Naive Bayes. Here we will use data with collection of SMS messages. It contains 5572 records of different messages together with 747 spam messages.\n",
        "\n",
        "`Use case:** You need to classify if a message is spam or not.`\n",
        "\n",
        "Note : Download the dataset from your canvas account\n",
        "\n",
        "Reference documentation: https://scikit-learn.org/stable/modules/naive_bayes.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8gBFkAaoVV1j"
      },
      "outputs": [],
      "source": [
        "#import pandas with alias pd\n",
        "#import metrics\n",
        "# import matplotlib\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8kHkHN-VV1l"
      },
      "source": [
        "### Preparing Data\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WiW5HeAxVV1l"
      },
      "outputs": [],
      "source": [
        "#Read SMSSpamCollection dataset\n",
        "docs = pd.read_csv(r\"E:/DataScience_and_DataAnalyst_Notes/Machine Learning/Naive Bayes classification/Dataset/SMSSpamCollection.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CKm0Ub5CVV1l",
        "outputId": "ee977ffa-7116-4db6-cd66-464ea3ef0e63"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>sms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Class                                                sms\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#print first 5 records\n",
        "docs.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LcFsNVpNVV1m",
        "outputId": "f3f6d1f0-bd70-4c93-e980-d5e17cab70ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# counting spam and ham instances\n",
        "ham_spam=docs.Class.value_counts()\n",
        "\n",
        "#print ham_spam\n",
        "print(ham_spam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBjR3c9JVV1n",
        "outputId": "d6ecddeb-c483-4bbe-a13e-c7ed57157eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spam % is  13.406317300789663\n"
          ]
        }
      ],
      "source": [
        "#print percentage of spam messages in your dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "K95943n4VV1n",
        "outputId": "ff35c809-9288-46bf-ddde-86570a14ea8f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>sms</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Class                                                sms  label\n",
              "0   ham  Go until jurong point, crazy.. Available only ...      0\n",
              "1   ham                      Ok lar... Joking wif u oni...      0\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
              "3   ham  U dun say so early hor... U c already then say...      0\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...      0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# mapping a column labels to ham as 0 and spam as 1\n",
        "docs['label'] =docs.Class.map({\"ham\":0,'spam':1})\n",
        "\n",
        "#print last 5 records of dataset\n",
        "docs.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dCwl4KWrVV1o",
        "outputId": "b6e16314-bf2f-46f7-ea34-38548daa21a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5572,)\n",
            "(5572,)\n"
          ]
        }
      ],
      "source": [
        "#Fetch all features \n",
        "X=docs.sms\n",
        "\n",
        "#Fetch label\n",
        "y=docs.label\n",
        "\n",
        "\n",
        "#print shape of X and y\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VoJf7LdQVV1o"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxHuwbsHVV1p"
      },
      "source": [
        "## Naive Bayes in scikit-learn\n",
        "\n",
        "scikit-learn implements three naive Bayes variants based on the same number of different probabilistic distributions: \n",
        "1. **Bernoulli :** This is a binary distribution useful when a feature can be present or absent.\n",
        "2. **multinomial :**This is a discrete distribution used whenever a feature must be represented by a whole number (for example, in natural language processing, it can be the frequency of a term)\n",
        "3.**Gaussian :** This is a continuous distribution characterized by its mean and variance.\n",
        "\n",
        "So here you think, which variant will you be using for your problem statement\n",
        "\n",
        "# **`WATCH ALL VIDEOS IN THE PORTAL`**\n",
        "## **`Watch Video 1 : NaiveBayes Intro`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hqxcqMZrVV1p",
        "outputId": "c321312a-0b34-4132-f722-e4faba11b36a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "710     4mths half price Orange line rental & latest c...\n",
              "3740                           Did you stitch his trouser\n",
              "2711    Hope you enjoyed your new content. text stop t...\n",
              "3155    Not heard from U4 a while. Call 4 rude chat pr...\n",
              "3748    Ü neva tell me how i noe... I'm not at home in...\n",
              "Name: sms, dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print X_train first 5 records\n",
        "X_train.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pXz-HTOVV1q"
      },
      "source": [
        "### vectorization of words.\n",
        "\n",
        "<p style='text-align: right;'> 20 points </p>\n",
        "\n",
        "\n",
        "Here you can see that your features are in form of sequence of words or you can say sentences. Now to feed this information into our algorithm we need make it in form of numbers.\n",
        "\n",
        "But how?\n",
        " \n",
        "Sklearn has awesome library to extract features from text. This library is called CountVectorizer: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "\n",
        "Imagine breaking X in individual words and putting them all in a bag. Then we pick all the unique words from the bag one by one and make a dictionary of unique words. \n",
        "\n",
        "This is called **vectorization of words**. We have the class ```CountVectorizer()``` in scikit learn to vectorize the words. Let us first see it in action before explaining it further.\n",
        "\n",
        "```Countvectorizer()``` will convert the documents into a set of unique words alphabetically sorted and indexed.\n",
        "**Stop Words**\n",
        "\n",
        "We can see a few trivial words such as  'and','is','of', etc. These words don't really make any difference in classyfying a document. These are called 'stop words'. So we would like to get rid of them. \n",
        "\n",
        "We can remove them by passing a parameter stop_words='english' while instantiating ```Countvectorizer()``` \n",
        "\n",
        "\n",
        "**Reference video:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY1iCYGym9oQ"
      },
      "source": [
        "## **`Watch Video 2: Text Analytics(Count Vectorizer)`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H0sxWrsnVV1r",
        "outputId": "fe4d14bf-51ff-46c0-f1a6-040f1f83bf09"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "CountVectorizer(stop_words='english')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#Instantiate CountVectorizer with stop_words\n",
        "vect = CountVectorizer(stop_words='english')\n",
        "\n",
        "\n",
        "# fit vect on your feature text (X_train)\n",
        "vect.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yipEeQx-VV1s"
      },
      "source": [
        "Here ```vect``` is an object of class ```CountVectorizer()```. This has a method called  ```fit()``` which converts a corpus of documents into a vector of unique words as shown below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4MwPQIiVV1s"
      },
      "source": [
        "Bam! So you have fit the features with X_train. Remember its not tranformed into vectors yet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lnrvJujlVV1s",
        "outputId": "0d051421-78a4-441a-87c3-acbe84b00320"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'4mths': 509,\n",
              " 'half': 3089,\n",
              " 'price': 5027,\n",
              " 'orange': 4626,\n",
              " 'line': 3852,\n",
              " 'rental': 5310,\n",
              " 'latest': 3763,\n",
              " 'camera': 1527,\n",
              " 'phones': 4822,\n",
              " 'free': 2780,\n",
              " 'phone': 4818,\n",
              " '11mths': 264,\n",
              " 'mobilesdirect': 4248,\n",
              " '08000938767': 50,\n",
              " 'update': 6673,\n",
              " 'or2stoptxt': 4624,\n",
              " 'cs': 1971,\n",
              " 'did': 2169,\n",
              " 'stitch': 6028,\n",
              " 'trouser': 6545,\n",
              " 'hope': 3260,\n",
              " 'enjoyed': 2436,\n",
              " 'new': 4442,\n",
              " 'content': 1867,\n",
              " 'text': 6321,\n",
              " 'stop': 6038,\n",
              " '61610': 563,\n",
              " 'unsubscribe': 6665,\n",
              " 'help': 3180,\n",
              " '08712400602450p': 98,\n",
              " 'provided': 5089,\n",
              " 'tones2you': 6473,\n",
              " 'uk': 6614,\n",
              " 'heard': 3159,\n",
              " 'u4': 6608,\n",
              " 'rude': 5443,\n",
              " 'chat': 1643,\n",
              " 'private': 5040,\n",
              " '01223585334': 5,\n",
              " 'cum': 1989,\n",
              " 'wan': 6852,\n",
              " '2c': 374,\n",
              " 'pics': 4837,\n",
              " 'gettin': 2913,\n",
              " 'shagged': 5628,\n",
              " 'pix': 4858,\n",
              " '8552': 660,\n",
              " '2end': 378,\n",
              " 'send': 5590,\n",
              " 'sam': 5487,\n",
              " 'xxx': 7127,\n",
              " 'neva': 4438,\n",
              " 'tell': 6289,\n",
              " 'noe': 4477,\n",
              " 'home': 3244,\n",
              " 'da': 2015,\n",
              " 'aft': 826,\n",
              " 'wat': 6876,\n",
              " 'wiskey': 7012,\n",
              " 'brandy': 1389,\n",
              " 'rum': 5450,\n",
              " 'gin': 2927,\n",
              " 'beer': 1209,\n",
              " 'vodka': 6798,\n",
              " 'scotch': 5535,\n",
              " 'shampain': 5637,\n",
              " 'wine': 6993,\n",
              " 'kudi': 3715,\n",
              " 'yarasu': 7142,\n",
              " 'dhina': 2156,\n",
              " 'vaazhthukkal': 6720,\n",
              " 'seeking': 5573,\n",
              " 'lady': 3732,\n",
              " 'street': 6056,\n",
              " 'freak': 2776,\n",
              " 'sheets': 5649,\n",
              " 'lol': 3910,\n",
              " 'drunkard': 2327,\n",
              " 'just': 3623,\n",
              " 'doing': 2259,\n",
              " 'hair': 3085,\n",
              " 'moment': 4265,\n",
              " 'yeah': 7149,\n",
              " 'tonight': 6475,\n",
              " 'wats': 6887,\n",
              " 'plan': 4867,\n",
              " 'turning': 6579,\n",
              " 'moms': 4267,\n",
              " 'telling': 6290,\n",
              " 'cancer': 1535,\n",
              " 'sister': 5745,\n",
              " 'won': 7041,\n",
              " 'calling': 1519,\n",
              " 'hurts': 3323,\n",
              " 'talk': 6234,\n",
              " 'love': 3953,\n",
              " 'coming': 1800,\n",
              " 'dinner': 2193,\n",
              " 'rite': 5396,\n",
              " 'dad': 2018,\n",
              " 'ask': 1032,\n",
              " 'confirm': 1843,\n",
              " 'wif': 6977,\n",
              " 'ah': 842,\n",
              " 'poor': 4931,\n",
              " 'baby': 1121,\n",
              " 'urfeeling': 6687,\n",
              " 'bettersn': 1243,\n",
              " 'luv': 3988,\n",
              " 'probthat': 5052,\n",
              " 'overdose': 4667,\n",
              " 'work': 7058,\n",
              " 'hey': 3198,\n",
              " 'careful': 1556,\n",
              " 'spk': 5938,\n",
              " 'sn': 5822,\n",
              " 'lots': 3942,\n",
              " 'lovejen': 3955,\n",
              " 'gam': 2856,\n",
              " 'gone': 2968,\n",
              " 'outstanding': 4664,\n",
              " 'innings': 3438,\n",
              " 'nice': 4453,\n",
              " 'working': 7062,\n",
              " 'haha': 3081,\n",
              " 'kidding': 3672,\n",
              " 'papa': 4705,\n",
              " 'needs': 4417,\n",
              " 'drugs': 2325,\n",
              " 'chief': 1677,\n",
              " 'bell': 1223,\n",
              " 'need': 4412,\n",
              " 'royal': 5432,\n",
              " 'visit': 6789,\n",
              " '1st': 324,\n",
              " 'june': 3618,\n",
              " 'ugh': 6610,\n",
              " 'long': 3917,\n",
              " 'day': 2054,\n",
              " 'exhausted': 2523,\n",
              " 'want': 6857,\n",
              " 'cuddle': 1984,\n",
              " 'nap': 4381,\n",
              " 'awesome': 1103,\n",
              " 'time': 6418,\n",
              " 'like': 3840,\n",
              " 'lt': 3974,\n",
              " 'gt': 3044,\n",
              " 'll': 3887,\n",
              " 'details': 2143,\n",
              " 'wee': 6916,\n",
              " 'bit': 1277,\n",
              " 'ok': 4578,\n",
              " 'lor': 3932,\n",
              " 'thk': 6376,\n",
              " 'tickets': 6407,\n",
              " 'cos': 1901,\n",
              " 'quite': 5149,\n",
              " 'late': 3760,\n",
              " 'look': 3921,\n",
              " 'ur': 6684,\n",
              " 'frens': 2791,\n",
              " 'darren': 2041,\n",
              " 'dont': 2269,\n",
              " 'know': 3700,\n",
              " 'bring': 1414,\n",
              " 'food': 2730,\n",
              " 'reason': 5224,\n",
              " 've': 6744,\n",
              " 'spoken': 5948,\n",
              " 'year': 7150,\n",
              " 'anyways': 947,\n",
              " 'great': 3020,\n",
              " 'week': 6918,\n",
              " 'best': 1237,\n",
              " 'exam': 2511,\n",
              " 'make': 4042,\n",
              " 'fucks': 2825,\n",
              " 'sake': 5476,\n",
              " 'yes': 7160,\n",
              " 'place': 4862,\n",
              " 'town': 6504,\n",
              " 'meet': 4130,\n",
              " 'exciting': 2515,\n",
              " 'adult': 806,\n",
              " 'singles': 5739,\n",
              " 'txt': 6590,\n",
              " '86688': 664,\n",
              " '150p': 293,\n",
              " 'msg': 4315,\n",
              " 'man': 4052,\n",
              " 'print': 5035,\n",
              " 'outs': 4660,\n",
              " 'room': 5418,\n",
              " 'think': 6368,\n",
              " 'saying': 5517,\n",
              " 'clearly': 1734,\n",
              " 'leave': 3793,\n",
              " 'come': 1794,\n",
              " 'st': 5972,\n",
              " 'andre': 912,\n",
              " 'virgil': 6783,\n",
              " 'cream': 1947,\n",
              " 'yoyyooo': 7179,\n",
              " 'change': 1623,\n",
              " 'permissions': 4789,\n",
              " 'drive': 2313,\n",
              " 'mac': 4013,\n",
              " 'usb': 6699,\n",
              " 'flash': 2692,\n",
              " 'sunshine': 6148,\n",
              " 'quiz': 5151,\n",
              " 'wkly': 7024,\n",
              " 'win': 6987,\n",
              " 'sony': 5865,\n",
              " 'dvd': 2350,\n",
              " 'player': 4875,\n",
              " 'country': 1914,\n",
              " 'algarve': 875,\n",
              " 'ansr': 927,\n",
              " '82277': 637,\n",
              " '50': 520,\n",
              " 'sp': 5898,\n",
              " 'tyrone': 6606,\n",
              " 'dear': 2066,\n",
              " 'th': 6333,\n",
              " 'birthday': 1275,\n",
              " 'loving': 3963,\n",
              " 'gopalettan': 2984,\n",
              " 'planning': 4871,\n",
              " 'small': 5796,\n",
              " 'gift': 2921,\n",
              " 'participate': 4724,\n",
              " 'welcome': 6933,\n",
              " 'contact': 1863,\n",
              " 'admin': 793,\n",
              " 'team': 6274,\n",
              " 'class': 1724,\n",
              " 'hours': 3282,\n",
              " 'sorry': 5877,\n",
              " 'okay': 4579,\n",
              " 'wait': 6834,\n",
              " 'rushing': 5458,\n",
              " 'school': 5527,\n",
              " 'rush': 5457,\n",
              " 'hungry': 3314,\n",
              " 'usually': 6712,\n",
              " 'stops': 6044,\n",
              " 'hella': 3177,\n",
              " 'weed': 6917,\n",
              " 'smoke': 5811,\n",
              " 'awarded': 1101,\n",
              " 'city': 1715,\n",
              " 'break': 1396,\n",
              " '200': 335,\n",
              " 'summer': 6139,\n",
              " 'shopping': 5681,\n",
              " 'spree': 5961,\n",
              " 'wk': 7020,\n",
              " 'store': 6046,\n",
              " '88039': 675,\n",
              " 'skilgme': 5759,\n",
              " 'tscs087147403231winawk': 6562,\n",
              " 'age16': 832,\n",
              " '50perwksub': 528,\n",
              " 'shall': 5635,\n",
              " 'pickle': 4836,\n",
              " 'isn': 3506,\n",
              " 'frnd': 2809,\n",
              " 'necesity': 4407,\n",
              " 'life': 3830,\n",
              " 'imagine': 3376,\n",
              " 'urself': 6697,\n",
              " 'witout': 7017,\n",
              " 'hw': 3328,\n",
              " 'feel': 2620,\n",
              " 'colleg': 1786,\n",
              " 'wth': 7102,\n",
              " 'cell': 1605,\n",
              " 'abt': 742,\n",
              " 'functions': 2833,\n",
              " 'thnk': 6378,\n",
              " 'events': 2491,\n",
              " 'espe': 2474,\n",
              " 'cared': 1553,\n",
              " 'missed': 4215,\n",
              " 'amp': 903,\n",
              " 'irritated': 3496,\n",
              " '4wrd': 517,\n",
              " 'frnds': 2810,\n",
              " 'wthout': 7103,\n",
              " 'live': 3880,\n",
              " 'jst': 3605,\n",
              " 'takecare': 6228,\n",
              " 'goodmorning': 2977,\n",
              " 'brum': 1437,\n",
              " 'thanks': 6337,\n",
              " 'putting': 5126,\n",
              " 'keeping': 3651,\n",
              " 'happy': 3120,\n",
              " 'soon': 5868,\n",
              " 'im': 3373,\n",
              " 'tellmiss': 6291,\n",
              " 'way': 6891,\n",
              " 'bloomberg': 1310,\n",
              " 'message': 4163,\n",
              " 'center': 1607,\n",
              " '447797706009': 482,\n",
              " 'apply': 969,\n",
              " 'future': 2842,\n",
              " 'http': 3298,\n",
              " 'careers': 1555,\n",
              " 'com': 1791,\n",
              " 'enjoy': 2435,\n",
              " 'plural': 4892,\n",
              " 'noun': 4515,\n",
              " 'research': 5331,\n",
              " 'sure': 6165,\n",
              " 'checking': 1656,\n",
              " 'happening': 3114,\n",
              " 'area': 991,\n",
              " 'aight': 850,\n",
              " 'sleeping': 5774,\n",
              " 'surfing': 6168,\n",
              " 'cool': 1888,\n",
              " 'breeze': 1406,\n",
              " 'bright': 1410,\n",
              " 'sun': 6142,\n",
              " 'fresh': 2793,\n",
              " 'flower': 2711,\n",
              " 'twittering': 6588,\n",
              " 'birds': 1270,\n",
              " 'waiting': 6837,\n",
              " 'wish': 7006,\n",
              " 'ringtone': 5389,\n",
              " 'order': 4630,\n",
              " 'reference': 5261,\n",
              " 'number': 4526,\n",
              " 'x49': 7114,\n",
              " 'mobile': 4246,\n",
              " 'charged': 1633,\n",
              " 'tone': 6470,\n",
              " 'arrive': 1016,\n",
              " 'customer': 2002,\n",
              " 'services': 5609,\n",
              " '09065989182': 214,\n",
              " 'colour': 1789,\n",
              " 'red': 5257,\n",
              " 'txtstar': 6598,\n",
              " 'does': 2245,\n",
              " 'uncle': 6626,\n",
              " 'timi': 6420,\n",
              " 'clearing': 1733,\n",
              " 'cars': 1569,\n",
              " 'getting': 2914,\n",
              " 'really': 5219,\n",
              " 'bad': 1128,\n",
              " 'totally': 6498,\n",
              " 'rejected': 5281,\n",
              " 'kinda': 3682,\n",
              " 'thing': 6366,\n",
              " 'sent': 5598,\n",
              " 'prices': 5028,\n",
              " 'mean': 4116,\n",
              " 'hi': 3202,\n",
              " 'darlin': 2038,\n",
              " 'london': 3914,\n",
              " 'smashed': 5801,\n",
              " 'driver': 2314,\n",
              " 'big': 1257,\n",
              " 'dent': 2118,\n",
              " 'missing': 4217,\n",
              " 'took': 6479,\n",
              " 'tablets': 6217,\n",
              " 'reaction': 5205,\n",
              " 'morning': 4289,\n",
              " 'going': 2959,\n",
              " 'intention': 3459,\n",
              " 'run': 5453,\n",
              " 'choose': 1700,\n",
              " 'clean': 1728,\n",
              " 'don': 2266,\n",
              " 'say': 5516,\n",
              " 'visitors': 6791,\n",
              " 'maybe': 4111,\n",
              " 'choice': 1698,\n",
              " 'wanted': 6859,\n",
              " 'embarassed': 2413,\n",
              " 'friend': 2800,\n",
              " 'wants': 6861,\n",
              " 'drop': 2319,\n",
              " 'buy': 1483,\n",
              " 'happened': 3113,\n",
              " 'tried': 6537,\n",
              " 'picking': 4835,\n",
              " 'various': 6735,\n",
              " 'points': 4914,\n",
              " 'yeovil': 7157,\n",
              " 'motor': 4298,\n",
              " 'project': 5064,\n",
              " '12': 266,\n",
              " '30': 412,\n",
              " 'max': 4106,\n",
              " 'easy': 2368,\n",
              " 'test': 6316,\n",
              " 'rd': 5199,\n",
              " 'fret': 2794,\n",
              " 'ovulation': 4673,\n",
              " 'strips': 6066,\n",
              " 'wont': 7048,\n",
              " 'til': 6416,\n",
              " 'march': 4072,\n",
              " 'postal': 4953,\n",
              " 'address': 790,\n",
              " 'alright': 887,\n",
              " 'loyalty': 3970,\n",
              " 'offer': 4560,\n",
              " 'nokia6650': 4485,\n",
              " '10': 244,\n",
              " 'txtauction': 6593,\n",
              " 'word': 7056,\n",
              " 'start': 5993,\n",
              " '81151': 632,\n",
              " '4t': 511,\n",
              " 'ctxt': 1982,\n",
              " 'tc': 6266,\n",
              " 'mtmsg': 4325,\n",
              " 'remember': 5295,\n",
              " 'alex': 873,\n",
              " 'pizza': 4860,\n",
              " 'av': 1084,\n",
              " 'wil': 6982,\n",
              " 'use': 6701,\n",
              " 'ta': 6214,\n",
              " 'urgent': 6688,\n",
              " 'trying': 6558,\n",
              " 'todays': 6454,\n",
              " 'draw': 2301,\n",
              " 'shows': 5701,\n",
              " '800': 617,\n",
              " 'prize': 5043,\n",
              " 'guaranteed': 3048,\n",
              " '09050001808': 158,\n",
              " 'land': 3740,\n",
              " 'claim': 1718,\n",
              " 'm95': 4008,\n",
              " 'valid12hrs': 6727,\n",
              " 'babe': 1119,\n",
              " 'lost': 3939,\n",
              " 'painful': 4690,\n",
              " 'personal': 4795,\n",
              " 'thought': 6384,\n",
              " 'try': 6556,\n",
              " 'everybody': 2492,\n",
              " 'recognises': 5250,\n",
              " 'subscribed': 6105,\n",
              " 'service': 5608,\n",
              " 'days': 2055,\n",
              " '82324': 638,\n",
              " 'helpline': 3185,\n",
              " '08706091795': 83,\n",
              " 'basket': 1164,\n",
              " 'mum': 4336,\n",
              " 'messages': 4165,\n",
              " 'got': 2988,\n",
              " 'actually': 781,\n",
              " 'rest': 5351,\n",
              " 'january': 3541,\n",
              " 'male': 4049,\n",
              " 'sale': 5480,\n",
              " 'hot': 3276,\n",
              " 'gay': 2877,\n",
              " 'cheaper': 1649,\n",
              " '08709222922': 88,\n",
              " 'national': 4391,\n",
              " 'rate': 5187,\n",
              " '5p': 548,\n",
              " 'min': 4187,\n",
              " 'cheap': 1648,\n",
              " '8p': 695,\n",
              " 'peak': 4765,\n",
              " 'texts': 6331,\n",
              " '08712460324': 108,\n",
              " '10p': 254,\n",
              " 'honesty': 3249,\n",
              " 'road': 5399,\n",
              " 'bank': 1146,\n",
              " 'tomorrow': 6469,\n",
              " 'tough': 6502,\n",
              " 'decisions': 2080,\n",
              " 'people': 4776,\n",
              " 'womdarfull': 7039,\n",
              " 'actor': 779,\n",
              " 'congrats': 1847,\n",
              " 'special': 5910,\n",
              " 'cinema': 1713,\n",
              " 'pass': 4731,\n",
              " '09061209465': 180,\n",
              " 'suprman': 6163,\n",
              " 'matrix3': 4101,\n",
              " 'starwars3': 5997,\n",
              " 'bx420': 1493,\n",
              " 'ip4': 3484,\n",
              " '5we': 552,\n",
              " '150pm': 295,\n",
              " 'miss': 4213,\n",
              " 'movie': 4304,\n",
              " 'juz': 3626,\n",
              " 'minute': 4202,\n",
              " 'decision': 2079,\n",
              " 'mah': 4031,\n",
              " 'watch': 6877,\n",
              " 'lar': 3751,\n",
              " 'tot': 6496,\n",
              " 'interested': 3460,\n",
              " 'care': 1551,\n",
              " 'sweet': 6191,\n",
              " 'dreams': 2305,\n",
              " 'ummifying': 6620,\n",
              " 'bye': 1495,\n",
              " 'gud': 3050,\n",
              " 'ni8': 4451,\n",
              " 'slp': 5794,\n",
              " 'swt': 6203,\n",
              " 'muah': 4330,\n",
              " 'youdoing': 7172,\n",
              " 'later': 3762,\n",
              " 'sar': 5495,\n",
              " 'money': 4270,\n",
              " '09050000460': 153,\n",
              " 'j89': 3526,\n",
              " 'po': 4897,\n",
              " 'box245c2150pm': 1364,\n",
              " 'issue': 3508,\n",
              " 'weigh': 6924,\n",
              " 'breathe': 1403,\n",
              " 'easier': 2363,\n",
              " 'regret': 5278,\n",
              " 'gr8': 3000,\n",
              " 'leaving': 3795,\n",
              " 'plans': 4872,\n",
              " 'havent': 3142,\n",
              " 'sir': 5742,\n",
              " 'group': 3034,\n",
              " 'mail': 4034,\n",
              " 'check': 1653,\n",
              " 'hit': 3216,\n",
              " 'cash': 1573,\n",
              " 'girl': 2928,\n",
              " '2004': 338,\n",
              " 'account': 760,\n",
              " 'statement': 5998,\n",
              " '07742676969': 27,\n",
              " '786': 608,\n",
              " 'unredeemed': 6661,\n",
              " 'bonus': 1332,\n",
              " '08719180248': 144,\n",
              " 'identifier': 3355,\n",
              " 'code': 1770,\n",
              " '45239': 489,\n",
              " 'expires': 2538,\n",
              " 'mins': 4200,\n",
              " 'busy': 1479,\n",
              " 'finish': 2670,\n",
              " 'looking': 3924,\n",
              " 'forward': 2761,\n",
              " 'finally': 2663,\n",
              " 'meeting': 4132,\n",
              " 'hmv': 3230,\n",
              " '500': 521,\n",
              " 'pounds': 4965,\n",
              " 'genuine': 2901,\n",
              " 'vouchers': 6808,\n",
              " 'answer': 928,\n",
              " 'questions': 5144,\n",
              " 'play': 4873,\n",
              " 'info': 3425,\n",
              " 'www': 7110,\n",
              " '100percent': 249,\n",
              " 'real': 5210,\n",
              " 'accidentally': 754,\n",
              " 'left': 3798,\n",
              " 'silent': 5726,\n",
              " 'night': 4460,\n",
              " 'didn': 2170,\n",
              " 'ya': 7134,\n",
              " 'tht': 6398,\n",
              " 'incident': 3399,\n",
              " 'good': 2972,\n",
              " 'problem': 5047,\n",
              " 'little': 3879,\n",
              " 'experience': 2534,\n",
              " 'understand': 6633,\n",
              " 'american': 895,\n",
              " 'voice': 6799,\n",
              " 'used': 6702,\n",
              " 'agents': 836,\n",
              " 'booked': 1336,\n",
              " 'things': 6367,\n",
              " 'boston': 1350,\n",
              " 'nyc': 4539,\n",
              " 'experiment': 2535,\n",
              " 'online': 4599,\n",
              " 'transaction': 6515,\n",
              " 'came': 1526,\n",
              " 'hostel': 3274,\n",
              " 'sleep': 5772,\n",
              " 'plz': 4895,\n",
              " 'hrishi': 3295,\n",
              " 'fuuuuck': 2843,\n",
              " 'sleepin': 5773,\n",
              " 'sup': 6150,\n",
              " 'dude': 2337,\n",
              " 'makin': 4045,\n",
              " 'weirdy': 6931,\n",
              " 'brownies': 1433,\n",
              " 'cookies': 1886,\n",
              " 'secret': 5560,\n",
              " 'admirer': 795,\n",
              " 'reveal': 5368,\n",
              " 'thinks': 6372,\n",
              " '09058094599': 175,\n",
              " 'oh': 4573,\n",
              " 'training': 6512,\n",
              " 'manual': 4066,\n",
              " 'tech': 6279,\n",
              " 'process': 5053,\n",
              " 'password': 4737,\n",
              " 'reset': 5337,\n",
              " 'troubleshooting': 6544,\n",
              " 'computerless': 1831,\n",
              " 'oreo': 4633,\n",
              " 'truffles': 6550,\n",
              " 'watching': 6880,\n",
              " 'tv': 6582,\n",
              " 'job': 3580,\n",
              " 'hoping': 3264,\n",
              " 'game': 2858,\n",
              " 'yesterday': 7162,\n",
              " 'touch': 6500,\n",
              " 'pls': 4888,\n",
              " 'fondly': 2725,\n",
              " 'bein': 1220,\n",
              " 'thot': 6382,\n",
              " 'abiola': 732,\n",
              " 'nite': 4470,\n",
              " 'pocay': 4907,\n",
              " 'wocay': 7035,\n",
              " '4eva': 502,\n",
              " 'promise': 5068,\n",
              " 'ring': 5387,\n",
              " '2morrowxxxx': 393,\n",
              " 'yup': 7189,\n",
              " 'thanx': 6342,\n",
              " 'reply': 5321,\n",
              " 'pick': 4833,\n",
              " 'heart': 3162,\n",
              " 'mind': 4190,\n",
              " 'wisdom': 7004,\n",
              " 'eyes': 2555,\n",
              " 'alwys': 891,\n",
              " 'panren': 4700,\n",
              " 'paru': 4729,\n",
              " 'wife': 6978,\n",
              " 'relax': 5286,\n",
              " 'wkend': 7021,\n",
              " 'fun': 2831,\n",
              " 'truly': 6551,\n",
              " 'forget': 2746,\n",
              " 'gbp': 2881,\n",
              " 'sms': 5817,\n",
              " 'approve': 975,\n",
              " 'panalam': 4695,\n",
              " 'posts': 4959,\n",
              " 'paid': 4688,\n",
              " 'commercial': 1804,\n",
              " 'hasbro': 3129,\n",
              " 'august': 1075,\n",
              " 'jump': 3616,\n",
              " 'hoops': 3258,\n",
              " 'shut': 5711,\n",
              " 'omg': 4592,\n",
              " 'dream': 2304,\n",
              " 'kids': 3673,\n",
              " 'boys': 1381,\n",
              " 'pissed': 4855,\n",
              " 'told': 6460,\n",
              " 'mark': 4076,\n",
              " 'changing': 1626,\n",
              " 'diapers': 2164,\n",
              " 'cause': 1588,\n",
              " 'owed': 4676,\n",
              " 'face': 2559,\n",
              " 'ey': 2553,\n",
              " 'calm': 1523,\n",
              " 'downon': 2292,\n",
              " 'theacusations': 6347,\n",
              " 'itxt': 3517,\n",
              " 'iwana': 3520,\n",
              " 'wotu': 7077,\n",
              " 'doin': 2257,\n",
              " 'thew': 6362,\n",
              " 'end': 2422,\n",
              " 'haventcn': 3143,\n",
              " 'ages': 837,\n",
              " 'up4': 6669,\n",
              " 'nething': 4432,\n",
              " 'sat': 5502,\n",
              " 'dramatic': 2299,\n",
              " 'schools': 5528,\n",
              " 'closed': 1742,\n",
              " 'apparently': 961,\n",
              " 'inch': 3397,\n",
              " 'snow': 5832,\n",
              " 'supposed': 6161,\n",
              " 'woke': 7036,\n",
              " 'blur': 1319,\n",
              " 'went': 6940,\n",
              " 'liao': 3821,\n",
              " 'oso': 4645,\n",
              " 'helloooo': 3179,\n",
              " 'wake': 6838,\n",
              " 'welcomes': 6934,\n",
              " 'joy': 3600,\n",
              " 'mrng': 4312,\n",
              " 'jason': 3546,\n",
              " 'says': 5518,\n",
              " 'gonna': 2970,\n",
              " 'mallika': 4051,\n",
              " 'sherawat': 5652,\n",
              " 'url': 6694,\n",
              " 'wa': 6823,\n",
              " 'openin': 4608,\n",
              " 'sentence': 5599,\n",
              " 'formal': 2753,\n",
              " 'fine': 2667,\n",
              " 'tt': 6565,\n",
              " 'eatin': 2371,\n",
              " 'puttin': 5125,\n",
              " 'weight': 6926,\n",
              " 'anythin': 944,\n",
              " 'tyler': 6602,\n",
              " 'minor': 4199,\n",
              " 'crisis': 1960,\n",
              " 'sooner': 5869,\n",
              " 'asap': 1024,\n",
              " 'erm': 2460,\n",
              " 'ill': 3369,\n",
              " '45pm': 490,\n",
              " 'park': 4720,\n",
              " 'treat': 6529,\n",
              " 'pending': 4773,\n",
              " 'respect': 5343,\n",
              " 'mother': 4293,\n",
              " 'mails': 4037,\n",
              " 'alrite': 888,\n",
              " 'hunny': 3316,\n",
              " 'wot': 7076,\n",
              " '2nite': 398,\n",
              " 'didnt': 2171,\n",
              " 'goin': 2958,\n",
              " 'jus': 3622,\n",
              " 'pub': 5101,\n",
              " 'instead': 3453,\n",
              " 'chillin': 1686,\n",
              " 'mo': 4242,\n",
              " 'bedroom': 1206,\n",
              " 'jen': 3559,\n",
              " 'aiyo': 860,\n",
              " 'meh': 4137,\n",
              " 'princess': 5034,\n",
              " 'times': 6419,\n",
              " 'thats': 6346,\n",
              " 'ew': 2507,\n",
              " 'friendship': 2803,\n",
              " 'poem': 4911,\n",
              " 'near': 4405,\n",
              " 'hear': 3158,\n",
              " 'fear': 2613,\n",
              " 'cheer': 1660,\n",
              " 'tear': 6275,\n",
              " 'added': 786,\n",
              " 'list': 3868,\n",
              " 'fullonsms': 2829,\n",
              " 'ignoring': 3363,\n",
              " 'dating': 2049,\n",
              " 'started': 5994,\n",
              " 'sport': 5954,\n",
              " 'radio': 5160,\n",
              " 'connection': 1851,\n",
              " 'coincidence': 1774,\n",
              " 'hook': 3257,\n",
              " 'means': 4120,\n",
              " 'right': 5383,\n",
              " 'valuable': 6728,\n",
              " 'situations': 5752,\n",
              " 'second': 5557,\n",
              " 'loosing': 3930,\n",
              " 'si': 5713,\n",
              " 'como': 1808,\n",
              " 'listened2the': 3871,\n",
              " 'plaid': 4866,\n",
              " 'album': 867,\n",
              " 'gd': 2884,\n",
              " 'air1': 854,\n",
              " 'hilarious': 3207,\n",
              " 'bought': 1354,\n",
              " 'braindance': 1386,\n",
              " 'comp': 1809,\n",
              " 'ofstuff': 4570,\n",
              " 'aphex': 953,\n",
              " 'abel': 728,\n",
              " 'hav2hear': 3139,\n",
              " 'xxxx': 7129,\n",
              " 'wana': 6854,\n",
              " 'praps': 4988,\n",
              " 'meant': 4121,\n",
              " 'goodo': 2981,\n",
              " 'stay': 6001,\n",
              " 'england': 2433,\n",
              " 'official': 4566,\n",
              " 'poly': 4918,\n",
              " 'flag': 2688,\n",
              " 'yer': 7159,\n",
              " '84199': 653,\n",
              " 'opt': 4618,\n",
              " 'eng': 2430,\n",
              " 'box39822': 1369,\n",
              " 'w111wx': 6814,\n",
              " 'honeybee': 3251,\n",
              " 'said': 5475,\n",
              " 'sweetest': 6192,\n",
              " 'world': 7065,\n",
              " 'god': 2954,\n",
              " 'laughed': 3767,\n",
              " 'havnt': 3147,\n",
              " 'met': 4170,\n",
              " 'person': 4794,\n",
              " 'reading': 5208,\n",
              " 'moral': 4285,\n",
              " 'crack': 1934,\n",
              " 'jokes': 3590,\n",
              " 'gm': 2943,\n",
              " 'gn': 2945,\n",
              " 'ge': 2886,\n",
              " 'study': 6082,\n",
              " 'tap': 6247,\n",
              " 'spile': 5931,\n",
              " 'seven': 5616,\n",
              " 'gas': 2870,\n",
              " 'broad': 1422,\n",
              " 'canal': 1530,\n",
              " 'wan2': 6853,\n",
              " 'greet': 3023,\n",
              " 'westlife': 6950,\n",
              " 'm8': 4006,\n",
              " 'currently': 1997,\n",
              " 'tour': 6503,\n",
              " 'unbreakable': 6625,\n",
              " 'untamed': 6667,\n",
              " 'unkempt': 6652,\n",
              " '83049': 640,\n",
              " 'cost': 1903,\n",
              " '50p': 526,\n",
              " 'std': 6006,\n",
              " 'drunk': 2326,\n",
              " 'motherfucker': 4294,\n",
              " 'textbuddy': 6324,\n",
              " 'horny': 3266,\n",
              " 'guys': 3068,\n",
              " '25p': 362,\n",
              " 'receive': 5237,\n",
              " 'search': 5552,\n",
              " 'postcode': 4955,\n",
              " 'gaytextbuddy': 2880,\n",
              " '89693': 690,\n",
              " '08715500022': 122,\n",
              " 'rpl': 5434,\n",
              " 'cnl': 1759,\n",
              " 'hiya': 3220,\n",
              " 'weekend': 6920,\n",
              " 'usual': 6711,\n",
              " 'ard': 990,\n",
              " 'smth': 5821,\n",
              " 'doc': 2239,\n",
              " 'gave': 2876,\n",
              " 'pain': 4689,\n",
              " 'meds': 4128,\n",
              " 'mahal': 4032,\n",
              " 'bus': 1473,\n",
              " 'decimal': 2078,\n",
              " 'cooking': 1887,\n",
              " 'oops': 4604,\n",
              " 'tomo': 6467,\n",
              " 'station': 5999,\n",
              " 'dhoni': 2157,\n",
              " 'luck': 3978,\n",
              " 'title': 6433,\n",
              " 'waking': 6839,\n",
              " 'afternoon': 828,\n",
              " 'church': 1710,\n",
              " 'holla': 3240,\n",
              " 'let': 3815,\n",
              " 'salad': 5477,\n",
              " 'desert': 2132,\n",
              " 'beers': 1210,\n",
              " 'news': 4447,\n",
              " 'freefone': 2784,\n",
              " '08006344447': 56,\n",
              " '1000': 246,\n",
              " '2000': 336,\n",
              " 'speak': 5908,\n",
              " 'operator': 4612,\n",
              " 'hr': 3294,\n",
              " 'trip': 6538,\n",
              " 'audition': 1072,\n",
              " 'wednesday': 6914,\n",
              " 'whats': 6955,\n",
              " 'printed': 5036,\n",
              " 'upstairs': 6682,\n",
              " 'wasnt': 6872,\n",
              " 'phoned': 4821,\n",
              " 'voda': 6796,\n",
              " 'numbers': 4527,\n",
              " 'ending': 2424,\n",
              " '1225': 270,\n",
              " 'selected': 5579,\n",
              " '50award': 523,\n",
              " 'match': 4094,\n",
              " '08712300220': 95,\n",
              " 'quoting': 5155,\n",
              " '3100': 424,\n",
              " 'standard': 5984,\n",
              " 'rates': 5188,\n",
              " 'app': 960,\n",
              " 'today': 6453,\n",
              " 'accept': 749,\n",
              " 'brother': 1429,\n",
              " 'lover': 3958,\n",
              " 'dear1': 2067,\n",
              " 'best1': 1238,\n",
              " 'clos1': 1740,\n",
              " 'lvblefrnd': 3993,\n",
              " 'jstfrnd': 3606,\n",
              " 'cutefrnd': 2007,\n",
              " 'lifpartnr': 3833,\n",
              " 'belovd': 1228,\n",
              " 'swtheart': 6204,\n",
              " 'bstfrnd': 1442,\n",
              " 'rply': 5435,\n",
              " 'enemy': 2428,\n",
              " 'bloo': 1307,\n",
              " 'bowl': 1358,\n",
              " 'urgnt': 6691,\n",
              " 'wating': 6885,\n",
              " 'difficult': 2181,\n",
              " 'girls': 2931,\n",
              " 'companion': 1811,\n",
              " 'chef': 1666,\n",
              " 'listener': 3872,\n",
              " 'organizer': 4636,\n",
              " 'boyfriend': 1380,\n",
              " 'sympathetic': 6207,\n",
              " 'athletic': 1054,\n",
              " 'warm': 6864,\n",
              " 'courageous': 1919,\n",
              " 'determined': 2145,\n",
              " 'true': 6548,\n",
              " 'dependable': 2125,\n",
              " 'intelligent': 3457,\n",
              " 'psychologist': 5098,\n",
              " 'pest': 4802,\n",
              " 'exterminator': 2550,\n",
              " 'psychiatrist': 5096,\n",
              " 'healer': 3156,\n",
              " 'stylist': 6094,\n",
              " 'aaniye': 722,\n",
              " 'pudunga': 5105,\n",
              " 'venaam': 6749,\n",
              " 'request': 5326,\n",
              " 'maangalyam': 4011,\n",
              " 'alaipayuthe': 866,\n",
              " 'set': 5611,\n",
              " 'callertune': 1516,\n",
              " 'callers': 1515,\n",
              " 'press': 5017,\n",
              " 'copy': 1893,\n",
              " 'friends': 2801,\n",
              " 'tirunelvai': 6428,\n",
              " 'lick': 3825,\n",
              " 'pussy': 5123,\n",
              " 'inside': 3447,\n",
              " 'office': 4564,\n",
              " 'filling': 2654,\n",
              " 'forms': 2757,\n",
              " 'textin': 6327,\n",
              " 'bout': 1356,\n",
              " 'worries': 7069,\n",
              " 'photo': 4824,\n",
              " 'shoot': 5678,\n",
              " ...}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check count of words in your features (Hint: Use vocabulary_ on CountVectorizer)\n",
        "vect.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Tn5A5sluVV1t",
        "outputId": "c0e1936d-9a35-4361-d7b3-b4942d46e204"
      },
      "outputs": [],
      "source": [
        "#Check how feature names separately in form of words( Hint: Use get_feature_names function on  CountVectorizer)\n",
        "#vect.get_feature_names()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqYNGStGVV1t"
      },
      "source": [
        "Now let's transform our training features. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SjhenI-rVV1t"
      },
      "outputs": [],
      "source": [
        "# transform feature data\n",
        "X_train_transformed = vect.transform(X_train)\n",
        "X_test_tranformed =vect.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qG93AGt1VV1t",
        "outputId": "04889b8a-202b-4bad-82b3-df47ba03eedd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "#Now let's see how our X_train data looks like after tranformation ( hint: convert it into array and then print )\n",
        "\n",
        "print(X_test_tranformed.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "q4ijNhWXVV1u",
        "outputId": "22f045dd-1af6-4de4-984e-dfb2d7bde65a"
      },
      "outputs": [],
      "source": [
        "# printing length of feature names\n",
        "print(len(vect.get_feature_name()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxO77ITgVV1u"
      },
      "source": [
        "So our final dictionary is made of 7204 words (after discarding the stop words). Now, to do classification, we need to represent all the documents with respect to these words in the form of features. \n",
        "\n",
        "Every document will be converted into a *feature vector* representing presence of these words in that document. Let's convert each of our training documents in to a feature vector.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "THrsV94PVV1u",
        "outputId": "128b21b3-686d-4998-8d02-b4b79c203089"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4179, 7204)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print shape of X_train_transformed\n",
        "X_train_transformed.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxmMhb7mVV1-"
      },
      "source": [
        "You can see X_tranformed is a 4179 x 7456 sparse matrix. It has 4179 rows for each of our 4179 documents and 7456 columns each \n",
        "for number of words of the dictionary which we just created. Let us print X_transformed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UdUV_J24VV1-",
        "outputId": "a2d24660-52c5-4ad2-f59d-fa73b30b0415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 50)\t1\n",
            "  (0, 264)\t1\n",
            "  (0, 509)\t1\n",
            "  (0, 1527)\t1\n",
            "  (0, 1971)\t1\n",
            "  (0, 2780)\t2\n",
            "  (0, 3089)\t1\n",
            "  (0, 3763)\t1\n",
            "  (0, 3852)\t1\n",
            "  (0, 4248)\t1\n",
            "  (0, 4624)\t1\n",
            "  (0, 4626)\t1\n",
            "  (0, 4818)\t1\n",
            "  (0, 4822)\t1\n",
            "  (0, 5027)\t1\n",
            "  (0, 5310)\t1\n",
            "  (0, 6673)\t1\n",
            "  (1, 2169)\t1\n",
            "  (1, 6028)\t1\n",
            "  (1, 6545)\t1\n",
            "  (2, 98)\t1\n",
            "  (2, 563)\t1\n",
            "  (2, 1867)\t1\n",
            "  (2, 2436)\t1\n",
            "  (2, 3180)\t1\n",
            "  :\t:\n",
            "  (4176, 3879)\t1\n",
            "  (4176, 4417)\t1\n",
            "  (4176, 5229)\t1\n",
            "  (4176, 6191)\t1\n",
            "  (4176, 7134)\t1\n",
            "  (4177, 254)\t1\n",
            "  (4177, 307)\t1\n",
            "  (4177, 358)\t1\n",
            "  (4177, 831)\t1\n",
            "  (4177, 2046)\t1\n",
            "  (4177, 2704)\t1\n",
            "  (4177, 3585)\t1\n",
            "  (4177, 3623)\t1\n",
            "  (4177, 4130)\t1\n",
            "  (4177, 4315)\t1\n",
            "  (4177, 4771)\t1\n",
            "  (4177, 5234)\t1\n",
            "  (4177, 5321)\t1\n",
            "  (4177, 5487)\t1\n",
            "  (4177, 5620)\t1\n",
            "  (4177, 6321)\t1\n",
            "  (4177, 6374)\t1\n",
            "  (4177, 6453)\t1\n",
            "  (4178, 1643)\t1\n",
            "  (4178, 5817)\t1\n"
          ]
        }
      ],
      "source": [
        "#Print X_train_transformed\n",
        "print(X_train_transformed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrs-ohizVV1_"
      },
      "source": [
        "This representation can be understood as follows:\n",
        "\n",
        "Consider first 4 rows of the output: (0,50), (0,264), (0,509) and (0,1552). It says that the first document (index 0) has \n",
        "50th , 264nd , 509th and 1552th 'word' present in the document, and that they appear only\n",
        "once/twice in the document- indicated by the right hand column entry. \n",
        "\n",
        "\n",
        "\n",
        "In real problems, you often work with large documents and vocabularies, and each document contains only a few words in the vocabulary. So it would be a waste of space to store the vocabulary in a typical dataframe, since most entries would be zero. Also, matrix products, additions etc. are much faster with sparse matrices. That's why we use sparse matrices to store the data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kQcvU8gxVV1_",
        "outputId": "3fb0344d-f1c9-4b8e-803a-74916286c749"
      },
      "outputs": [],
      "source": [
        "#Print feature names\n",
        "vect.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRxuxmIPVV1_",
        "outputId": "e8ce962a-dacd-477e-e8ec-e56f861565bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>008704050406</th>\n",
              "      <th>0121</th>\n",
              "      <th>01223585236</th>\n",
              "      <th>01223585334</th>\n",
              "      <th>0125698789</th>\n",
              "      <th>02</th>\n",
              "      <th>0207</th>\n",
              "      <th>02072069400</th>\n",
              "      <th>...</th>\n",
              "      <th>zed</th>\n",
              "      <th>zeros</th>\n",
              "      <th>zhong</th>\n",
              "      <th>zindgi</th>\n",
              "      <th>zoe</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zouk</th>\n",
              "      <th>zyada</th>\n",
              "      <th>èn</th>\n",
              "      <th>〨ud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4174</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4176</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4177</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4178</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4179 rows × 7204 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      00  000  008704050406  0121  01223585236  01223585334  0125698789  02  \\\n",
              "0      0    0             0     0            0            0           0   0   \n",
              "1      0    0             0     0            0            0           0   0   \n",
              "2      0    0             0     0            0            0           0   0   \n",
              "3      0    0             0     0            0            1           0   0   \n",
              "4      0    0             0     0            0            0           0   0   \n",
              "...   ..  ...           ...   ...          ...          ...         ...  ..   \n",
              "4174   0    0             0     0            0            0           0   0   \n",
              "4175   0    0             0     0            0            0           0   0   \n",
              "4176   0    0             0     0            0            0           0   0   \n",
              "4177   0    0             0     0            0            0           0   0   \n",
              "4178   0    0             0     0            0            0           0   0   \n",
              "\n",
              "      0207  02072069400  ...  zed  zeros  zhong  zindgi  zoe  zoom  zouk  \\\n",
              "0        0            0  ...    0      0      0       0    0     0     0   \n",
              "1        0            0  ...    0      0      0       0    0     0     0   \n",
              "2        0            0  ...    0      0      0       0    0     0     0   \n",
              "3        0            0  ...    0      0      0       0    0     0     0   \n",
              "4        0            0  ...    0      0      0       0    0     0     0   \n",
              "...    ...          ...  ...  ...    ...    ...     ...  ...   ...   ...   \n",
              "4174     0            0  ...    0      0      0       0    0     0     0   \n",
              "4175     0            0  ...    0      0      0       0    0     0     0   \n",
              "4176     0            0  ...    0      0      0       0    0     0     0   \n",
              "4177     0            0  ...    0      0      0       0    0     0     0   \n",
              "4178     0            0  ...    0      0      0       0    0     0     0   \n",
              "\n",
              "      zyada  èn  〨ud  \n",
              "0         0   0    0  \n",
              "1         0   0    0  \n",
              "2         0   0    0  \n",
              "3         0   0    0  \n",
              "4         0   0    0  \n",
              "...     ...  ..  ...  \n",
              "4174      0   0    0  \n",
              "4175      0   0    0  \n",
              "4176      0   0    0  \n",
              "4177      0   0    0  \n",
              "4178      0   0    0  \n",
              "\n",
              "[4179 rows x 7204 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''converting X_train_transformed matrix to dataframe (Hint:X_train_transformed \n",
        "should be in an array form and columns as vector's feature name )'''\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl7gGxKlVV1_"
      },
      "source": [
        "This table shows how many times a particular word occurs in document. In other words, this is a frequency table of the words.\n",
        "A corpus of documents can thus be represented by a matrix with one row per document and one column per\n",
        "token (e.g. word) occurring in the corpus.\n",
        "\n",
        "We call vectorization the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the \"Bag of Words\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56SiePUBVV1_"
      },
      "source": [
        "#### So, the 4 steps for vectorization are as follows\n",
        "\n",
        "- Import\n",
        "- Instantiate\n",
        "- Fit \n",
        "- Transform\n",
        "\n",
        "Let us summarise all we have done till now:\n",
        "\n",
        "- ```vect.fit(train)``` learns the vocabulary of the training data\n",
        "- ```vect.transform(train)``` uses the fitted vocabulary to build a document-term matrix from the training data\n",
        "- ```vect.transform(test)``` uses the fitted vocabulary to build a document-term matrix from the testing data (and ignores tokens it hasn't seen before)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdFpOqeKVV2A"
      },
      "source": [
        "## Applying Naive Bayes algorithm\n",
        "\n",
        "Wohoo! so now you can see how your textual features are converted into feature vectors which are in numeric form. Alright, now you training data is ready to be fed into your algorithm\n",
        "\n",
        "We will try using Bernoulli Naive Bayes algorithm first\n",
        "\n",
        "Reference doc: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html\n",
        "\n",
        "\n",
        "### 1. Bernoulli Naive Bayes\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n",
        "\n",
        "\n",
        "Reference video on working of bernoulli Naive Bayes:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW1qTPIGnVaY"
      },
      "source": [
        "## **`Watch Video 3: Bernoulli Naive Bayes`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5TVbAvxiVV2A",
        "outputId": "d96dc048-5a45-4cd9-c144-81bec7b28cfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9770279971284996\n"
          ]
        }
      ],
      "source": [
        "#import BernoulliNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "# instantiate bernoulli NB object\n",
        "bnb = BernoulliNB()\n",
        "\n",
        "# fit model on training dataset\n",
        "bnb.fit(X_train_transformed,y_train)\n",
        "# predict class of y\n",
        "y_pred_class = bnb.predict(X_test_tranformed)\n",
        "\n",
        "# predict probability on y\n",
        "y_pred_proba = bnb.predict_proba(X_test_tranformed)\n",
        "\n",
        "# print accuracy score \n",
        "print(metrics.accuracy_score(y_test,y_pred_class))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1K8PjrVVV2A"
      },
      "source": [
        "### Classification metrics\n",
        "\n",
        "Reference video:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi4f9X8Cng7O"
      },
      "source": [
        "## **`Watch Video 4 : Confusion Matrix`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iQq_T8cwVV2A",
        "outputId": "5bc20046-83f3-4ac5-df7f-043b80a0a5aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1207    1]\n",
            " [  31  154]]\n"
          ]
        }
      ],
      "source": [
        "# get confusion metrics\n",
        "confusion = metrics.confusion_matrix(y_test,y_pred_class)\n",
        "\n",
        "#print confusion metrics\n",
        "print(confusion)\n",
        "#Get True negative, Flase positive, Flase negative and True positive using confusion metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOhhGFGEVV2A"
      },
      "source": [
        "TO know what exactly specificity and sensitivity are, then do watch this video :\n",
        "\n",
        "We hope by watching this small video you got your big doubts cleared! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6abmuQinsvk"
      },
      "source": [
        "## **`Watch Video 5 : sensitivity & specificity`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUqJRnBOVV2A",
        "outputId": "11bb09a4-9f15-41fa-a505-c45bf52a83ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sensitivity 0.8324324324324325\n"
          ]
        }
      ],
      "source": [
        "# Calculate sensitivity using confusion metrics\n",
        "sensitivity = \n",
        "\n",
        "#Print sensitivity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6JDxQS2VV2B",
        "outputId": "006f6fd9-9e6e-435f-c8e7-75db0de49ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "specificity 0.9991721854304636\n"
          ]
        }
      ],
      "source": [
        "# Calculate specificity using confusion metrics\n",
        "specificity =\n",
        "\n",
        "#Print specificity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpCabnloVV2B",
        "outputId": "c820fb3c-c745-48c6-da9d-116e387cfce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.9935483870967742\n"
          ]
        }
      ],
      "source": [
        "# Calculate precision using confusion metrics\n",
        "precision = \n",
        "\n",
        "# print precision\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apt9V0czVV2B"
      },
      "source": [
        "Let us print precision, recall and f1 score  using metrics sklearn library classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6aunfrsYVV2B",
        "outputId": "f0f67cde-02e5-4114-b03d-012b392f04c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99      1208\n",
            "           1       0.99      0.83      0.91       185\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.98      0.92      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#import classification_report\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred_class))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPDdLCLKVV2B"
      },
      "source": [
        "Well done! we hope you remember what are these data science terminologies( precision, recall and f1-score) mean.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKJq2z1sVV2B"
      },
      "source": [
        "## Creating ROC curve\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n",
        "\n",
        "\n",
        "AUC - ROC curve is a performance measurement for the classification problems at various threshold settings. It tells how much the model is capable of distinguishing between classes. Higher the AUC, the better the model is at predicting 0 classes as 0 and 1 classes as 1\n",
        "\n",
        "Reference video:\n",
        "Reference doc: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2-r4nz9n4dD"
      },
      "source": [
        "## **`Watch Video 6: ROC AUC.`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Fp0GV8fXVV2B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9967692858421334\n"
          ]
        }
      ],
      "source": [
        "# import roc_curve and and auc\n",
        "from sklearn.metrics  import roc_curve,auc\n",
        "\n",
        "#Calculate false_positive_rate , true_positive_rate and thresholds using roc_curve\n",
        "false_positive_rate, true_positive_rate, thresholds =roc_curve(y_test,y_pred_proba[:,1])\n",
        "\n",
        "\n",
        "#Calculate area under curve\n",
        "roc_auc = auc(false_positive_rate,true_positive_rate)\n",
        "print(roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IjECj7wQVV2C",
        "outputId": "92eb7649-3c2f-472c-b4a9-5e8d98effd6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9967692858421334\n"
          ]
        }
      ],
      "source": [
        "#Print area under the curve\n",
        "print(roc_auc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kkcXe-xVV2C"
      },
      "source": [
        "The ROC curve is plotted with TPR against the FPR where TPR is on the y-axis and FPR is on the x-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lygo6UkJVV2C",
        "outputId": "030d309b-c928-4d53-cb3e-efd9c054c69d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plotting the ROC curve (false_positive_rate vs true_positive_rate )\n",
        "\n",
        "\n",
        "plt.plot(false_positive_rate,true_positive_rate)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TCdBksWVV2C"
      },
      "source": [
        "From above plot what do you understand? \n",
        "\n",
        "Do comment below on the same!"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "dwvtJ4lFVV2C"
      },
      "source": [
        "#comment: \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zYlBiLxVV2C"
      },
      "source": [
        "Good job so far!\n",
        "\n",
        "Now we will try out Multinomial Naive Bayes to solve this use case. SO let's get started.\n",
        "\n",
        "Reference doc :<a href= \"https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#:~:text=The%20multinomial%20Naive%20Bayes%20classifier,tf%2Didf%20may%20also%20work\">sklearn document </a>\n",
        "\n",
        "### 2. Multinomial Naive Bayes\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CysICqFQoEFi"
      },
      "source": [
        "## **`Watch Video 7 : Multinomial Naive bayes`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "eadXLUgvVV2D",
        "outputId": "417ca564-4bee-459a-92e3-ea5c960bba65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9877961234745154\n"
          ]
        }
      ],
      "source": [
        "#import BernoulliNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# instantiate bernoulli NB object\n",
        "bnb = MultinomialNB()\n",
        "\n",
        "# fit model on training dataset\n",
        "bnb.fit(X_train_transformed,y_train)\n",
        "# predict class of y\n",
        "y_pred_class = bnb.predict(X_test_tranformed)\n",
        "\n",
        "# predict probability on y\n",
        "y_pred_proba = bnb.predict_proba(X_test_tranformed)\n",
        "\n",
        "# print accuracy score \n",
        "print(metrics.accuracy_score(y_test,y_pred_class))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ35VFKaVV2D"
      },
      "source": [
        "#### Evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Vbjt3CU6VV2D",
        "outputId": "ac6531a9-cb9b-4fca-eab8-6de0ee8a3994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1066  142]\n",
            " [  11  174]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.88      0.93      1208\n",
            "           1       0.55      0.94      0.69       185\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.77      0.91      0.81      1393\n",
            "weighted avg       0.93      0.89      0.90      1393\n",
            "\n"
          ]
        }
      ],
      "source": [
        "confusion = metrics.confusion_matrix(y_test,y_pred_class)\n",
        "\n",
        "print(confusion)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred_class))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1d3I83qVV2D"
      },
      "source": [
        "Let us print precision, recall and f1 score  using metrics sklearn library classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVZkMjw-VV2D",
        "outputId": "22701350-2234-44c7-9dba-f6e0794957a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      1208\n",
            "           1       0.96      0.95      0.95       185\n",
            "\n",
            "    accuracy                           0.99      1393\n",
            "   macro avg       0.98      0.97      0.97      1393\n",
            "weighted avg       0.99      0.99      0.99      1393\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#import classification_report\n",
        "\n",
        "\n",
        "#Print Precision, recall, f1-score and support \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgRz4eNiVV2D"
      },
      "source": [
        "#### ROC curve\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeHtG_VeVV2D"
      },
      "outputs": [],
      "source": [
        "# import roc_curve and and auc\n",
        "\n",
        "\n",
        "#Calculate false_positive_rate , true_positive_rate and thresholds using roc_curve\n",
        "false_positive_rate, true_positive_rate, thresholds = \n",
        "\n",
        "\n",
        "#Calculate area under curve\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDeQ1cQwVV2E"
      },
      "source": [
        "The ROC curve is plotted with TPR against the FPR where TPR is on the y-axis and FPR is on the x-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLxbo4B9VV2E",
        "outputId": "ca591359-a7cc-4ce2-8a31-071cf9bac8d2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plotting the ROC curve (false_positive_rate vs true_positive_rate )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1EQAAA2VV2E"
      },
      "source": [
        "Do comment on above on the plot!"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "QevE2J3jVV2E"
      },
      "source": [
        "#comment: \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPWZikb7VV2E"
      },
      "source": [
        "Though guassian naive bayes is applicable in this case, but still we try to implement guassian Niave Bayes as well here and see how differently it performs form the ohter two variant we already saw.\n",
        "\n",
        "Reference doc: https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes\n",
        "\n",
        "### 3. Guassian Naive Bayes\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n",
        "\n",
        "\n",
        "Reference video: https://www.youtube.com/watch?v=H3EjCKtlVog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFybb63ooSLo"
      },
      "source": [
        "## **`Watch Video 8: Gaussian Naive bayes`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zc0U4_SQVV2E",
        "outputId": "34ba71c1-d690-4075-da76-65591e4b98a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8901651112706389\n"
          ]
        }
      ],
      "source": [
        "# import GaussianNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# instantiate bernoulli NB object\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# fit model on training dataset\n",
        "gnb.fit(X_train_transformed.toarray(),y_train)\n",
        "# predict class of y\n",
        "y_pred_class = gnb.predict(X_test_tranformed.toarray())\n",
        "\n",
        "# predict probability on y\n",
        "y_pred_proba = gnb.predict_proba(X_test_tranformed.toarray())\n",
        "\n",
        "# print accuracy score \n",
        "print(metrics.accuracy_score(y_test,y_pred_class))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qce21FglVV2E"
      },
      "source": [
        "Note: If you get an error while doing above cell then just try to understand the code and try to change the code accordingly.\n",
        "\n",
        "#### Evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "JpTv7FB_VV2E",
        "outputId": "aa9e31fa-b0f7-4fd9-f1b0-4cb08358a583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1066  142]\n",
            " [  11  174]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.88      0.93      1208\n",
            "           1       0.55      0.94      0.69       185\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.77      0.91      0.81      1393\n",
            "weighted avg       0.93      0.89      0.90      1393\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# get confusion metrics\n",
        "confusion = metrics.confusion_matrix(y_test,y_pred_class)\n",
        "\n",
        "print(confusion)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred_class))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVYh2a_6VV2F"
      },
      "source": [
        "Let us print precision, recall and f1 score  using metrics sklearn library classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P-4D5gEVV2F",
        "outputId": "212d5d92-588c-4e73-cd0b-1a233a010ce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.88      0.93      1208\n",
            "           1       0.55      0.94      0.69       185\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.77      0.91      0.81      1393\n",
            "weighted avg       0.93      0.89      0.90      1393\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#import classification_report\n",
        "\n",
        "\n",
        "#Print Precision, recall, f1-score and support \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svDmk0syVV2F"
      },
      "source": [
        "####  ROC Curve\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EijEfsgEVV2F"
      },
      "outputs": [],
      "source": [
        "# import roc_curve and and auc\n",
        "\n",
        "\n",
        "#Calculate false_positive_rate , true_positive_rate and thresholds using roc_curve\n",
        "false_positive_rate, true_positive_rate, thresholds =\n",
        "\n",
        "\n",
        "#Calculate area under curve\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KY__0cFVV2F",
        "outputId": "0ad28424-c3ff-4f46-a3be-a56bd7e3273c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plotting the ROC curve (false_positive_rate vs true_positive_rate )\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHa96vU_VV2F"
      },
      "source": [
        "Do comment on above on the plot!\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "HqU3jkGPVV2F"
      },
      "source": [
        "#comment: \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pctIEoMSVV2F"
      },
      "source": [
        "If you will see all three variant result of Naive Bayes, performance of multinomial is better than the other two variant.\n",
        "\n",
        "Let's print accuracy of all three below:\n",
        "\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LRizzjzVV2F",
        "outputId": "c39db322-bafe-4399-b69f-45d34ce62596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Burnoulli : 0.9770279971284996\n",
            "Multinomial : 0.9877961234745154\n",
            "Guassian : 0.8901651112706389\n"
          ]
        }
      ],
      "source": [
        "# print accuracy score of all three Naive Bayes algorithms.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s25CxjavVV2G"
      },
      "source": [
        "And hence it's proved that Multinomial Naive Bayes would solve this usecase of classifying spam messages correctly. \n",
        "\n",
        "So here with this conclusion that Multinomial works better here because frequency of each feature word has occured more than once in many cases, and hence multinomial fits  better in this case compared to Bernoulli and guassian Naive Bayes\n",
        "\n",
        "So well Done.\n",
        "\n",
        "\n",
        "**Note:** Please do watch all the videos provided in assignments, as it's purpose is to give clarity on each topic to get basics right inorder to crack any data science interview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE8u_sZlVV2G"
      },
      "source": [
        "---------------------------------\n",
        "\n",
        "# Cheers:) you have completed the 17th milestone challenge too. \n",
        "\n",
        "--------------------------------\n",
        "\n",
        "# FeedBack Time\n",
        "We hope you’ve enjoyed this course so far. We’re committed to help you use \"AI for All\" course to its full potential, so that you have a great learning experience. And that’s why we need your help in form of a feedback here.\n",
        "\n",
        "Please fill this feedback form https://docs.google.com/forms/d/e/1FAIpQLSfjBmH0yJSSA34IhSVx4h2eDMgOAeG4Dk-yHid__NMTk3Hq5g/viewform"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "56SiePUBVV1_"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
